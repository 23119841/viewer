from PIL import Image
import numpy as np
import onnxruntime as rt
import os
import sys
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
import zetane as ztn

# Original script: ONNX Model Zoo
# https://github.com/onnx/models/tree/master/vision/body_analysis/emotion_ferplus

directory = os.path.dirname(__file__)
def preprocess(image_path):
    input_shape = (1, 1, 64, 64)
    img = Image.open(image_path)
    img = img.resize((64, 64), Image.ANTIALIAS)
    img_data = np.array(img)
    img_data = np.resize(img_data, input_shape)
    return img_data

def emotion_map(classes, N=1):
    """Take the most probable labels (output of postprocess) and returns the
    top N emotional labels that fit the picture."""
    emotion_table = {'neutral':0, 'happiness':1, 'surprise':2, 'sadness':3,
                     'anger':4, 'disgust':5, 'fear':6, 'contempt':7}
    emotion_keys = list(emotion_table.keys())
    emotions = []
    for i in range(N):
        emotions.append(emotion_keys[classes[i]])
    return emotions

def softmax(x):
    """Compute softmax values (probabilities from 0 to 1) for each possible label."""
    x = x.reshape(-1)
    e_x = np.exp(x - np.max(x))
    return e_x / e_x.sum(axis=0)

def postprocess(scores):
    """This function takes the scores generated by the network and
    returns the class IDs in decreasing order of probability."""
    prob = softmax(scores)
    prob = np.squeeze(prob)
    classes = np.argsort(prob)[::-1]
    return classes


# Launch Zetane
zcontext = ztn.Context().launch()
zonnx = zcontext.model()
zimg_input = zcontext.image()

# provide the name of the model and width and height of the images for the variables
model = directory+r'/emotion-ferplus-8.onnx'
width = 64
height = 64
filepath = directory+r'/happy.jpg'

preprocess_image = preprocess(filepath)
x = np.array(preprocess_image).astype('float32')
#np.save('testferemotions.npy', x)
zimg_input.position(2, 7, 0).scale(.5, .5, .5).rotation(0, -1.57, 0).update(filepath=filepath)  #.rotation(0, 0, -1.57).

zonnx.visualize_inputs(False)
zonnx.onnx(model).update(inputs = x)

# Load onnx file and run inference
session = rt.InferenceSession(model)
output_name = session.get_outputs()[0].name
input_name = session.get_inputs()[0].name
result = session.run([output_name], {input_name: x})[0]

test_outputs = []
output_processed = emotion_map(postprocess(result))[0]
test_outputs.append(output_processed)
test_outputs_string = ' '.join(map(str, test_outputs))
ztxt_answer = zcontext.text("Output: ").position(0, 6, 0).font('slab').font_size(0.16).billboard(True) \
    .color((1, 1, 1)).highlight((0.5, 0.5, 1)).update()
ztxt_answer.text("Output:"+ test_outputs_string).position(2, 6, 0).update()
